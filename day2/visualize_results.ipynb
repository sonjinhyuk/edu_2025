{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e98b45c3",
   "metadata": {},
   "source": [
    "# IV. 실습: 예측 결과와 시각화\n",
    "\n",
    "## 강의 목표\n",
    "- 모델의 예측 결과를 다양한 형태로 시각화합니다.\n",
    "- 확률 분포, Confusion Matrix 등을 통해 예측 결과를 쉽게 이해할 수 있습니다.\n",
    "- 데이터 후처리를 통해 **설명가능성(Interpretability)** 를 확보합니다.\n",
    "- WordCloud로 악성/정상 트래픽의 주요 단어 분포를 파악합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf3c33",
   "metadata": {},
   "source": [
    "## 4.1 예측 확률값 시각화\n",
    "\n",
    "모델이 각 샘플에 대해 예측한 \"확률값\"은 단순한 라벨보다 훨씬 더 많은 정보를 담고 있습니다.  \n",
    "이 확률값 분포를 시각화함으로써 모델의 **자신감(confidence)**,  \n",
    "그리고 **불확실성(uncertainty)** 을 직관적으로 이해할 수 있습니다.\n",
    "\n",
    "예를 들어:\n",
    "- 확률이 0.95 이상인 샘플은 모델이 **거의 확신하고 있음**\n",
    "- 확률이 0.5 근처인 샘플은 **혼란스러워함** → 추가 확인 필요\n",
    "\n",
    "이를 시각화하면 다음과 같은 통찰을 얻을 수 있습니다:\n",
    "- 모델이 자주 **혼동하는 구간**\n",
    "- 악성/정상 중 **특정 클래스에 대한 확신도 차이**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic' \n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "\n",
    "CLASS_NAMES = [\n",
    "    'Benign',\n",
    "    'BEanking_motet_Family',\n",
    "    'Banking_Zeus_Family',\n",
    "    'Banking_Other',\n",
    "    'Infostealer',\n",
    "    'RAT',\n",
    "    'Exploit_Kit',\n",
    "    'Malspam_Phishing',\n",
    "    'Ransomware',\n",
    "    'Recon_C2',\n",
    "    'Other_Generic',\n",
    "    'Cobalt_Strike'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25697a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 예측 결과 파일 로딩 (이전 실습에서 생성된 validation_result_all.csv 사용)\n",
    "df = pd.read_csv(\"validation_result.csv\")\n",
    "\n",
    "# 예측값, 정답값은 숫자 클래스 (int), 확률은 0~1\n",
    "df[\"correct\"] = df[\"target\"] == df[\"output\"]\n",
    "\n",
    "# 전체 확률 분포 히스토그램\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df[\"preds\"], bins=50, kde=True)\n",
    "plt.title(\"전체 예측 확률값 분포\")\n",
    "plt.xlabel(\"예측 확률값 (confidence)\")\n",
    "plt.ylabel(\"샘플 수\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 클래스별 확률 boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=\"target\", y=\"preds\", data=df)\n",
    "# x축 클래스명으로 대체\n",
    "plt.xticks(ticks=range(len(CLASS_NAMES)), labels=CLASS_NAMES, rotation=45, ha='right')\n",
    "plt.title(\"클래스별 예측 확률 boxplot (target 기준)\")\n",
    "plt.xlabel(\"실제 클래스 (target)\")\n",
    "plt.ylabel(\"예측 확률값\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b31cef",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71817008",
   "metadata": {},
   "source": [
    "예측 확률값 시각화 해석\n",
    "### 1. 전체 예측 확률값 분포\n",
    "\n",
    "- 대부분의 예측 확률이 **0.95 ~ 1.0 구간에 몰려 있음**  \n",
    "  → 모델이 대부분의 샘플에 대해 **매우 확신(confident)** 하고 있음을 의미  \n",
    "- 0.5~0.9 사이의 구간은 거의 없음  \n",
    "  → **애매한 판단(uncertainty)** 은 드문 편  \n",
    "- 확률값이 낮은 일부 구간(0.2~0.4)에 소수의 샘플 존재  \n",
    "  → 이는 **오탐/미탐 가능성이 있는 영역**으로 해석할 수 있음\n",
    "\n",
    "---\n",
    "\n",
    "### 2. 클래스별 예측 확률 boxplot\n",
    "\n",
    "- 대부분의 클래스에서 예측 확률이 매우 높음 (상자 대부분이 0.95~1.0)  \n",
    "  → 모델이 **정답 클래스를 잘 구분하고 있음**  \n",
    "- 하지만 일부 클래스(예: 클래스 6번 Exploit_Kit)에서는 분산이 큼  \n",
    "  → 예측 확률이 낮은 샘플이 많아 **모델이 덜 확신하거나 혼동하는 클래스**일 수 있음  \n",
    "- Outlier 점들이 아래로 길게 뻗은 클래스는 **모델이 종종 불확실한 판단을 내리는 경향이 있음**\n",
    "\n",
    "- 주요 클래스별 특징 요약\n",
    "  - `Benign`: 대부분 예측 확률이 0.99 이상으로 모델이 매우 확신하는 경우가 많음. (정상 탐지에 자신 있음)\n",
    "  - `Exploit_Kit`: 분포가 넓고 박스가 큼 → 모델의 예측 불확실성이 존재함.\n",
    "  - `Malspam_Phishing`, `Banking_*`: 높은 예측 확률과 작은 분산 → 잘 학습된 패턴.\n",
    "  - `Recon_C2`, `Other_Generic`, `Cobalt_Strike`: 일부 이상값 존재. 특정 샘플에서 확신이 낮은 경우 있음.\n",
    "\n",
    "---\n",
    "\n",
    "#### 활용 방안\n",
    "\n",
    "- **모델 신뢰성 평가**: 어떤 클래스는 모델이 항상 높은 확신을 가지는 반면, 어떤 클래스는 낮은 확신을 보임.\n",
    "- **임계값 조정 시 기준**: 예측 확률이 낮은 클래스에 대해서는 threshold를 재조정하거나 후처리 로직을 추가할 수 있음.\n",
    "- **XAI와 연계**: 왜 특정 클래스의 확률이 낮았는지 원인을 분석하기 위한 기반 자료로 활용 가능\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a42cfb",
   "metadata": {},
   "source": [
    "### 4.2 Confusion Matrix 실습 (confusion matrix 기반 모델 평가)\n",
    "- 분류기의 전체 성능을 한눈에 시각화합니다.\n",
    "- True Positive / False Positive / False Negative / True Negative 비율을 직관적으로 확인합니다.\n",
    "- 모델이 잘 맞춘 영역과 자주 틀리는 클래스 간 상관관계를 파악할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a13003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df = pd.read_csv(\"validation_result.csv\")\n",
    "\n",
    "y_true = df[\"target\"]\n",
    "y_pred = df[\"output\"]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=CLASS_NAMES,\n",
    "            yticklabels=CLASS_NAMES)\n",
    "plt.xlabel(\"예측 클래스 (output)\")\n",
    "plt.ylabel(\"실제 클래스 (target)\")\n",
    "plt.title(\"Confusion Matrix (예측 vs 실제)\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee061226",
   "metadata": {},
   "source": [
    "- 대각선에 가까울수록 모델이 정확하게 예측한 경우입니다 (True Positive).\n",
    "- 비대각선 셀의 값이 클수록, 클래스 간 혼동이 있는 경우입니다.\n",
    "\n",
    "예시:\n",
    "- 만약 `Infostealer` (클래스 4)의 행에서 `Benign` (클래스 0) 열의 값이 높다면,\n",
    "  → Infostealer를 정상으로 잘못 예측한 경우가 많다는 뜻입니다. (False Negative)\n",
    "\n",
    "- `Benign`의 행에서 다른 악성 클래스 열로 예측된 경우가 많다면,\n",
    "  → 정상 트래픽을 악성으로 잘못 탐지하는 경우입니다. (False Positive)\n",
    "\n",
    "이 시각화를 통해:\n",
    "- 어떤 악성 클래스가 탐지가 잘 되는지 (TP)\n",
    "- 어떤 클래스가 자주 오탐되는지 (FP/FN)\n",
    "를 한눈에 파악할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ca9d5",
   "metadata": {},
   "source": [
    "## Confusion Matrix 분석 결과 해석\n",
    "\n",
    "Confusion Matrix는 모델의 예측값과 실제 라벨 간의 관계를 정리한 행렬로, 분류 성능을 직관적으로 파악할 수 있는 도구입니다. 각 셀의 숫자는 `(실제 클래스, 예측 클래스)` 쌍에 해당하는 예측 횟수를 의미합니다.\n",
    "\n",
    "### 주요 관찰 포인트\n",
    "\n",
    "- **Benign (정상 트래픽)**  \n",
    "  - 총 269,332건이 정상으로 정확히 예측됨.\n",
    "  - 그러나 악성으로 잘못 예측된 경우도 존재 (예: 148건은 Emotet, 13건은 Zeus 등으로 오탐).\n",
    "\n",
    "- **Banking 계열 (Emotet, Zeus, Other)**  \n",
    "  - `Banking_Emotet_Family`: 257,297건 정확 예측.\n",
    "  - `Banking_Zeus_Family`: 일부는 Emotet(1030), Other(10716)과 혼동.\n",
    "  - `Banking_Other`: 총 116,703건 정확 예측했으나, Zeus(10716), Emotet(10227)와 다소 혼선 있음.\n",
    "\n",
    "- **Infostealer**  \n",
    "  - 17,314건을 정확히 예측.\n",
    "  - 다만 Emotet(1702), Zeus(31) 등으로 일부 잘못 분류됨 → 타 Banking 계열과 혼동 가능성.\n",
    "\n",
    "- **Exploit_Kit**  \n",
    "  - 6,473건 정확 예측. 그러나 Benign(778), Emotet(250), Other(134)로 다소 오탐 존재.\n",
    "\n",
    "- **Malspam_Phishing**  \n",
    "  - 5,333건 정확 예측.\n",
    "  - Emotet(678), Zeus(65)와 상당수 혼동 → 비슷한 이메일 기반 특성 가능성.\n",
    "\n",
    "- **Ransomware**  \n",
    "  - 1,377건 정확 예측.\n",
    "  - Benign(193), Emotet(44) 등으로 일부 오탐.\n",
    "\n",
    "- **Recon_C2 / Other_Generic / Cobalt_Strike**  \n",
    "  - Recon_C2: 24,104건 정확 예측, 다만 Benign(3,770)으로 많이 오탐됨 → 탐지 기준 약함.\n",
    "  - Other_Generic: 18,546건 정확 예측. Benign(19), Emotet(1,040)과 일부 혼동.\n",
    "  - Cobalt_Strike: 11,797건 정확 예측, 하지만 Emotet(1,518), Zeus(72) 등으로 분류된 경우 있음.\n",
    "\n",
    "---\n",
    "\n",
    "### 추가 설명\n",
    "\n",
    "- **대각선이 진할수록** 해당 클래스는 잘 예측되었음을 의미.\n",
    "- **대각선 바깥의 값**은 오탐(FP), 미탐(FN)에 해당함.\n",
    "- 특히 `Emotet`, `Zeus`, `Infostealer` 간의 혼동이 빈번하므로 추가적인 전처리/특징 강화 필요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0583fa2",
   "metadata": {},
   "source": [
    "## 실습: 클래스별 ROC Curve 시각화\n",
    "\n",
    "이 실습에서는 다중 클래스 분류에서 **각 클래스별 ROC Curve**를 확인합니다.\n",
    "\n",
    "### 학습 목표\n",
    "- ROC Curve의 개념을 이해하고 민감도(Recall)와 특이도(Specificity)의 관계 파악\n",
    "- 모델이 클래스별로 얼마나 잘 구분하는지 시각적으로 확인\n",
    "- Word Cloud 기반 XAI 해석 전, 모델의 전반적 구분 성능 이해\n",
    "\n",
    "### 데이터 구성\n",
    "- `target`: 실제 레이블\n",
    "- `probs`: 모델의 클래스별 예측 확률 (softmax 결과)\n",
    "\n",
    "### 결과 예시\n",
    "- 각 클래스에 대해 ROC Curve가 그려지며, AUC(곡선 아래 면적)를 통해 성능 정량화\n",
    "- AUC 값이 1에 가까울수록 해당 클래스에 대한 분류가 잘 되었음을 의미\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e577c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"validation_result.csv\")\n",
    "y_true = df[\"target\"].values\n",
    "y_score = np.vstack(df[\"preds\"].values)\n",
    "\n",
    "y_bin = label_binarize(y_true, classes=list(range(len(CLASS_NAMES))))\n",
    "print(y_bin)\n",
    "print(y_bin.shape)\n",
    "n_classes = y_score.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e336583-5f48-4b90-8261-403d66972cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, n_classes))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_bin[:, i], y_score[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color=colors[i], lw=2, label=f\"{CLASS_NAMES[i]} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('클래스별 ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748169b",
   "metadata": {},
   "source": [
    "## ROC Curve 해석 (Benign 클래스 기준)\n",
    "\n",
    "- **True Positive Rate (TPR, 민감도)** vs **False Positive Rate (FPR)** 를 비교한 그래프입니다.\n",
    "- 그래프 위쪽에 위치할수록 좋은 모델이며, **완벽한 분류기는 왼쪽 위 모서리에 가까운 곡선을 보입니다.**\n",
    "\n",
    "---\n",
    "\n",
    "### 현재 ROC Curve의 특징\n",
    "- AUC (Area Under Curve) 값은 **0.72**로, **기준선(0.5)보다 높지만 우수한 성능은 아님**을 의미합니다.\n",
    "- **Benign 클래스에 대한 구분 성능이 다소 떨어짐**을 시사합니다.\n",
    "  - FPR이 높은 구간에서도 TPR이 완만하게 증가 → 혼동이 있다는 뜻.\n",
    "\n",
    "---\n",
    "\n",
    "### 왜 AUC는 낮을까?\n",
    "\n",
    "> 전체 정확도나 F1-score는 높지만, AUC는 낮을 수 있는 대표적인 이유:\n",
    "\n",
    "1. **클래스 불균형**  \n",
    "   - Benign 클래스가 데이터셋에서 매우 큰 비중을 차지할 경우, ROC는 오히려 성능을 낮게 평가할 수 있습니다.  \n",
    "   - 즉, 다수 클래스의 'True Negative'가 많아 **FPR이 높아지기 쉬움**.\n",
    "\n",
    "2. **모델의 출력 확률 분포가 치우쳐 있을 경우**  \n",
    "   - Benign으로 예측할 때 **확신(Confidence)이 높지 않거나**,  \n",
    "     **다른 클래스와의 경계가 애매**할 경우, TPR이 낮아질 수 있습니다.\n",
    "\n",
    "3. **ROC Curve는 '확률 예측의 품질'을 평가**  \n",
    "   - 단순히 정답/오답이 아니라 **확률 예측이 얼마나 잘 구분되는지를 본다는 점**에서,  \n",
    "     F1-score와 다른 성격의 지표입니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 보충 설명\n",
    "\n",
    "- 정확도, F1-score → **이진 결정 후의 결과 평가**\n",
    "- ROC-AUC → **모델이 얼마나 잘 \"점수 기반으로\" 구분하는지를 평가**\n",
    "\n",
    "---\n",
    "\n",
    "### 결론\n",
    "\n",
    "- **AUC가 낮다고 모델이 무조건 나쁘다는 뜻은 아님**\n",
    "- 특히 **다중 클래스 분류 + 클래스 불균형 상황**에서는  \n",
    "  **정확도나 F1-score와 AUC가 다르게 나올 수 있음**\n",
    "- 다양한 지표를 함께 보고 판단해야 하며,  \n",
    "  **Benign 클래스의 AUC 개선을 위해 정규화, 샘플링, threshold 조정 등을 고려**할 수 있음.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952832a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CSV 파일 로딩\n",
    "df = pd.read_csv(\"validation_result_all.csv\")\n",
    "\n",
    "df['class_name'] = CLASS_NAMES\n",
    "\n",
    "# 그래프 스타일 설정\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df['class_name'], df['f1'], color='skyblue')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"클래스별 F1-score\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a6540-c7f0-40ff-af09-7ca64e247529",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c480897",
   "metadata": {},
   "source": [
    "## 클래스별 성능 요약 테이블 해석\n",
    "\n",
    "이 표는 모델이 각 클래스를 얼마나 잘 분류했는지를 보여주는 상세한 성능 분석 자료입니다.\n",
    "\n",
    "| 항목 | 설명 |\n",
    "|------|------|\n",
    "| class | 클래스 ID (0: Benign, 1~11: 악성 유형별) |\n",
    "| support | 해당 클래스의 실제 샘플 수 |\n",
    "| precision | 해당 클래스로 예측한 것 중 실제 맞춘 비율 |\n",
    "| recall | 실제 해당 클래스를 모델이 얼마나 잘 맞췄는지 |\n",
    "| f1 | precision과 recall의 조화 평균 |\n",
    "| accuracy_classwise | TP + TN / 전체, 해당 클래스 중심 정확도 |\n",
    "| tp / fp / fn / tn | 혼동 행렬 기반 지표 |\n",
    "| prevalence | 전체 샘플 중 해당 클래스 비중 (불균형 확인용) |\n",
    "\n",
    "---\n",
    "\n",
    "### 주요 포인트 요약\n",
    "\n",
    "- **Benign (class 0)** 은 데이터의 34.7%를 차지하며, recall=0.9992로 거의 완벽하게 감지됨\n",
    "- **Banking 관련 (class 1~3)** 은 전체의 51.5%를 차지하고 있으며 precision/recall 모두 높음\n",
    "- **저빈도 클래스 (e.g., class 8 Ransomware, class 7 Malspam)** 은 recall이 0.8 수준으로 상대적으로 낮음 → 모델이 일부 놓치고 있음\n",
    "- **Recon_C2 (class 9)** 는 데이터 비중은 적지만 상대적으로 높은 f1 점수 확보\n",
    "- 전반적으로 precision과 recall의 균형이 양호하며, class imbalance에도 불구하고 모델이 잘 학습된 모습\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a2a5a",
   "metadata": {},
   "source": [
    "## ☁️ WordCloud 기반 XAI (설명용)\n",
    "\n",
    "- 각 클래스의 텍스트 데이터를 수집하고, 등장 빈도가 높은 단어들을 시각화하여\n",
    "  모델이 어떤 단어에 반응했을 가능성이 높은지를 파악합니다.\n",
    "  \n",
    "- WordCloud는 다음과 같은 목적에 활용할 수 있습니다:\n",
    "  - 클래스별 주요 키워드 직관적 비교\n",
    "  - 오탐/미탐 사례에서 공통된 단어 또는 특징 추출\n",
    "  - 초보자에게 XAI 개념을 쉽게 설명하는 도구로 적합\n",
    "\n",
    "---\n",
    "\n",
    "### 예시\n",
    "\n",
    "- **Benign** 클래스:\n",
    "  - 정상 사이트 관련 단어: `user-agent`, `host`, `keep-alive`, `accept`\n",
    "- **Malspam/Phishing** 클래스:\n",
    "  - 악성 이메일, 다운로드 관련 단어: `exe`, `zip`, `form`, `invoice`, `click`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c520be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import data_load\n",
    "# data setting\n",
    "data_base_dir = \"./model_data/\"\n",
    "bert_file = \"bert_inputs.txt\"\n",
    "MAXLEN = 512\n",
    "nlp_data_label = data_load(base_dir=data_base_dir, bert_flie=bert_file, MAXLEN=MAXLEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2ecae2",
   "metadata": {},
   "source": [
    "#### Data setting\n",
    "- payload만 활용하기 위해 전처리 진행\n",
    "- ex)\n",
    " > 'Detected Protocol: HTTP(S) Entropy: 5.28 Encryption Status: Possibly Structured Data Signature: 474554202f6d6564 (first 8 bytes) Length: 3840 bytes Readable ASCII Data: GET /media/system/js/jquery-1.6.5.min.js HTTP/1.1Accept: */*Referer: http://[redacted] Accept-Language: en-USUser-Agent: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0)Accept-Encoding: gzip, deflateHost: www.insightcrime.orgConnecti'\n",
    " \n",
    " >GET /media/system/js/jquery-1.6.5.min.js HTTP/1.1Accept: */*Referer: http://[redacted] Accept-Language: en-USUser-Agent: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0)Accept-Encoding: gzip, deflateHost: www.insightcrime.orgConnecti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_data = {}\n",
    "nlp_datas = nlp_data_label[0]\n",
    "nlp_labels = nlp_data_label[1]\n",
    "for text, label in zip(nlp_datas, nlp_labels):\n",
    "    temp_list = []\n",
    "    if label in labels_data:\n",
    "        temp_list = labels_data[label]\n",
    "    else:\n",
    "        temp_list = []\n",
    "    temp_list.append(text.split(\"Readable ASCII Data: \")[-1])\n",
    "    labels_data[label] = temp_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e051f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "def get_wc(all_tokens, class_id, output_name=None):\n",
    "    word_freq = Counter(all_tokens)\n",
    "    wc = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n",
    "    # 시각화 및 저장\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Class {class_id}: {CLASS_NAMES[class_id]}\")\n",
    "    plt.tight_layout()\n",
    "    if output_name is None:\n",
    "        plt.savefig(f\"wordcloud_by_class/class_{class_id}_{CLASS_NAMES[class_id]}.png\")\n",
    "    else:\n",
    "        plt.savefig(f\"wordcloud_by_class/{output_name}.png\")\n",
    "    plt.close()\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "def is_valid_token(token):\n",
    "    return (\n",
    "        re.fullmatch(r\"[a-z]{2,}\", token)\n",
    "        and token not in ENGLISH_STOP_WORDS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695216b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from utils.TH_BERT import tokenizer\n",
    "\n",
    "\n",
    "os.makedirs(\"wordcloud_by_class\", exist_ok=True)\n",
    "\n",
    "for class_id in labels_data.keys():\n",
    "    texts = labels_data.get(class_id)\n",
    "    \n",
    "    all_tokens = []\n",
    "    for text in texts:\n",
    "        tokens = tokenizer.tokenize(text.lower())\n",
    "        tokens = [\n",
    "            t for t in tokens \n",
    "            if t not in tokenizer.all_special_tokens\n",
    "            and not t.startswith(\"##\")\n",
    "            and is_valid_token(t)\n",
    "        ]\n",
    "        all_tokens.extend(tokens)\n",
    "    \n",
    "    get_wc(all_tokens, class_id)\n",
    "\n",
    "print(\"디토큰화 기반 WordCloud 저장 완료 (wordcloud_by_class 폴더)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd85b5",
   "metadata": {},
   "source": [
    "### Class 0: Benign - WordCloud 해석\n",
    "![Benign WordCloud](./wordcloud_by_class/class_0_Benign.png)\n",
    "- **주요 키워드:** `search`, `https`, `kr`, `root`, `ns`, `ss`, `version`, `agent`, `application`, `get`, `content`, `host`, `api`, `options`, `type`, `science`, `discover`, `length`, `site`, `data`\n",
    "\n",
    "---\n",
    "\n",
    "#### 해석 요약:\n",
    "\n",
    "- 이 WordCloud는 모델이 **정상 트래픽(Benign)** 으로 분류한 데이터들에서 등장한 단어들을 시각화한 것입니다.\n",
    "- 상위 키워드 대부분이 **정적 웹 페이지 구성 요소** 또는 **일반 API 호출 구조**에 가까운 단어들로 구성되어 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "#### 키워드 기반 분석:\n",
    "\n",
    "| 키워드 | 의미 | 해석 |\n",
    "|--------|------|------|\n",
    "| `https`, `get`, `host`, `api`, `options`, `agent` | HTTP 통신에서 일반적으로 사용되는 요청 헤더 키워드 | 정상적인 웹브라우저 요청의 흔적 |\n",
    "| `kr`, `co`, `com`, `org` | 도메인 또는 국가코드 | 실제 상업/연구 사이트 접속 가능성 |\n",
    "| `science`, `search`, `discover` | 검색 및 정보 관련 키워드 | 검색 엔진 또는 학술 정보 페이지 등 |\n",
    "| `application`, `version`, `content`, `type` | 소프트웨어/웹서버 메타 정보 | 브라우저 설정, 파일 MIME 등 일반 통신 요소 |\n",
    "\n",
    "---\n",
    "\n",
    "#### 전처리 설명\n",
    "\n",
    "- 원래는 `/`, `%`, `@` 등의 **특수문자**가 포함되어 있었지만, WordCloud의 **가독성 향상**을 위해 제거함.\n",
    "- 대신 의미 있는 단어들이 더 잘 드러나도록 **알파벳과 숫자 기반 키워드 중심으로 시각화**함.\n",
    "\n",
    "---\n",
    "\n",
    "#### 초심자를 위한 해석 팁\n",
    "\n",
    "> \"왜 이런 단어들이 중요한가요?\"\n",
    "\n",
    "- 악성 트래픽 탐지 모델을 만들 때, 어떤 요청이 정상인지 아닌지를 구분하는 기준은 **패턴의 차이**입니다.\n",
    "- 정상 트래픽에서는 보통 `search`, `api`, `https`, `content` 등 **웹서비스 이용 과정에서 흔히 나타나는 단어**들이 포함됩니다.\n",
    "- WordCloud는 이처럼 **빈도 중심의 시각화**를 통해 **정상과 비정상의 차이**를 직관적으로 보여주는 데 유용합니다.\n",
    "\n",
    "---\n",
    "\n",
    "#### SHAP, LIME은 왜 안썼나요?\n",
    "\n",
    "- SHAP, LIME 등은 강력한 **모델 해석 도구**이지만, 초심자 입장에서 코드를 이해하고 활용하기에는 진입장벽이 높습니다.\n",
    "- 이 실습에서는 먼저 WordCloud 기반의 **기초적인 인사이트 도출**을 통해 모델의 동작을 직관적으로 이해하는 것을 목표로 합니다.\n",
    "- 이후 고급 해석 기법으로 확장할 수 있도록 학습 기반을 마련합니다.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307df3e4",
   "metadata": {},
   "source": [
    "# 클래스별 WordCloud 해석 (선택 클래스 3종)\n",
    "\n",
    "복잡한 SHAP, LIME 등의 정량적 XAI 대신 **WordCloud**를 활용하여 각 클래스의 특징 단어를 시각적으로 해석했습니다. 특수문자 제거, 토큰화 및 디토큰화 전처리를 적용하였고, 그럼에도 불구하고 해석에 애매함이 존재할 수 있음을 감안해 설명을 진행합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 선정 클래스 요약\n",
    "\n",
    "| Class ID | Class Name           | 선정 이유 요약                                                             |\n",
    "|----------|----------------------|----------------------------------------------------------------------------|\n",
    "| 1        | Banking_Emotet_Family| 메일/서버 관련 단어가 많아 공격 패턴 설명에 적합                           |\n",
    "| 5        | RAT                  | `validation`, `control`, `online` 등 특징 단어가 명확하여 설명 가능        |\n",
    "| 7        | Malspam_Phishing     | 피싱 공격에 연관된 단어 (`express`, `installer`, `origin` 등)가 다수 등장 |\n",
    "\n",
    "---\n",
    "\n",
    "## Class 1: `Banking_Emotet_Family`\n",
    "![Benign WordCloud](./wordcloud_by_class/class_1_Banking_Emotet_Family.png)\n",
    "- **주요 단어**: `https`, `com`, `mail`, `query`, `agent`, `server`, `cache`, `protocol`\n",
    "- **해석**:\n",
    "  - `mail`, `query`, `agent` → 메일을 기반으로 한 공격 흐름 가능성 시사\n",
    "  - `cache`, `server`, `keep-alive` → 웹 기반 자원 요청 또는 중간자 공격 추정\n",
    "  - `protocol`, `type`, `host` → HTTP 계열의 정형화된 구조 내 악성 요소 삽입 가능성\n",
    "\n",
    "---\n",
    "\n",
    "## Class 5: `RAT (Remote Access Trojan)`\n",
    "![Benign WordCloud](./wordcloud_by_class/class_5_RAT.png)\n",
    "\n",
    "- **주요 단어**: `com`, `validation`, `control`, `online`, `ua`, `hosting`, `fresh`, `trust`\n",
    "- **해석**:\n",
    "  - `control`, `validation`, `online` → 명령제어(C2) 및 클라이언트 상태 점검 과정 존재 시사\n",
    "  - `hosting`, `fresh`, `trust` → 정상 호스팅/신뢰 단어로 위장한 악성 통신 특징\n",
    "  - `ua`, `pt`, `rat`, `ov` 등 일부 코드/지표들은 분석상 오탐 가능성도 내포\n",
    "\n",
    "---\n",
    "\n",
    "## Class 7: `Malspam_Phishing`\n",
    "![Benign WordCloud](./wordcloud_by_class/class_7_Malspam_Phishing.png)\n",
    "\n",
    "- **주요 단어**: `http`, `keep`, `alive`, `origin`, `express`, `installer`, `found`, `allow`\n",
    "- **해석**:\n",
    "  - `express`, `origin`, `installer` → 설치 유도형 피싱 메일 혹은 웹 설치파일 다운로드 유도 가능성\n",
    "  - `keep-alive`, `control`, `cache` → 지속 연결 유지 및 세션 악용 시도\n",
    "  - `allow`, `not`, `we`, `us` → 사용자 권한 요청 및 허용 유도 시도 표현 포함\n",
    "\n",
    "---\n",
    "\n",
    "> ❗ 참고: WordCloud 기반 해석은 **정확한 공격 분석**이 아닌 **시각적 개연성 확인용**으로 사용됩니다. 실제 공격 분석에는 정량 분석 및 샘플 디코딩이 필수입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e9dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "inaccuracy_df = pd.read_csv(\"inaccuracy_samples.csv\")\n",
    "wordcloud_tokens_by_class = {}  # 클래스별 토큰 저장용 dict\n",
    "for class_id in sorted(inaccuracy_df[\"target\"].unique()):\n",
    "    texts = inaccuracy_df[inaccuracy_df['target'] == class_id]['text']\n",
    "    if texts is not np.nan:\n",
    "        print(texts)\n",
    "    else:\n",
    "        continue\n",
    "    all_tokens = []\n",
    "    for text in texts:\n",
    "        try:\n",
    "        \ttokens = tokenizer.tokenize(text.lower())\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        tokens = [\n",
    "            t for t in tokens \n",
    "            if t not in tokenizer.all_special_tokens\n",
    "            and not t.startswith(\"##\")\n",
    "            and is_valid_token(t)\n",
    "        ]\n",
    "        all_tokens.extend(tokens)\n",
    "    output_name = f\"inaccuracy_wordcloud_{class_id}_{CLASS_NAMES[class_id]}\"\n",
    "    wordcloud_tokens_by_class[class_id] = all_tokens\n",
    "    get_wc(all_tokens, class_id, output_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ff4da",
   "metadata": {},
   "source": [
    "### 오탐 클래스 분석 - Class 0: Benign\n",
    "\n",
    "![Benign WordCloud](./wordcloud_by_class/inaccuracy_wordcloud_0_Benign.png)\n",
    "\n",
    "#### 주요 키워드\n",
    "- **data**, **byte**, **protocol**, **det**, **status**, **length**, **entropy**, **content**, **signature**, **structure** 등\n",
    "\n",
    "#### 분석 요약\n",
    "Benign 클래스의 오탐 탐지에서 눈에 띄는 키워드들은 실제 사용자 데이터라기보다는 **프로토콜 분석**에서 발생한 용어들이 많이 포함되어 있습니다.\n",
    "\n",
    "예를 들어:\n",
    "- `entropy`, `signature`, `status`, `structure` 등의 단어는 **보안 도구의 분석 과정**에서 자동 생성된 메타 정보일 가능성이 높습니다.\n",
    "- `possibly`, `read`, `det`, `protocol` 등의 단어들도 **추론 메시지 또는 분석 결과의 일부 표현**일 가능성이 있습니다.\n",
    "\n",
    "이러한 특성 때문에, 모델은 이를 오히려 **악성 행위 탐지에 활용되는 정황 정보로 착각**할 수 있으며, **Benign임에도 불구하고 악성으로 잘못 분류하는 오탐**이 발생한 것으로 해석됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f395c19",
   "metadata": {},
   "source": [
    "### Class 1: Banking_Emotet_Family\n",
    "![Benign WordCloud](./wordcloud_by_class/inaccuracy_wordcloud_1_Banking_Emotet_Family.png)\n",
    "\n",
    "#### 주요 단어\n",
    "- protocol, query, answer, data, byte, read, flag, signature, status\n",
    "\n",
    "#### 해석\n",
    "Emotet은 전형적인 뱅킹 악성코드로, 초기 스팸 이메일 → 매크로 → 다운로더 → 모듈 설치의 흐름을 탑니다.\n",
    "`query`, `answer`, `flag` 등은 내부에서 DNS/HTTP 요청을 통한 C2 연결을 시도하거나, 네트워크 기반 활동에서 파생된 것으로 추정됩니다.\n",
    "`signature`, `status`, `possibly` 등은 탐지 로직이 적용된 흔적이기도 하며, 이로 인해 benign 트래픽과 구분이 어려워 오탐이 발생했을 수 있습니다.\n",
    "\n",
    "### Class 3: Banking_Other\n",
    "![Benign WordCloud](./wordcloud_by_class/inaccuracy_wordcloud_3_Banking_Other.png)\n",
    "\n",
    "#### 주요 단어\n",
    "- data, byte, http, user, windows, answer, agent, status\n",
    "\n",
    "#### 해석\n",
    "기타 뱅킹 악성코드를 포함한 이 클래스는 악성 행위가 비교적 모호하거나 다양한 유형이 혼합된 경우입니다.\n",
    "특히 `http`, `windows`, `agent`, `user` 등은 정상적인 소프트웨어나 benign한 행위와 중복될 수 있어,\n",
    "트래픽 구조가 일반적인 요청과 유사한 경우 오탐 가능성이 높습니다.\n",
    "`agent`, `alive`, `host`는 HTTP Header 또는 프로토콜 레벨에서 공통적으로 등장하는 필드이며,\n",
    "이 역시 탐지 모델이 혼동했을 여지가 있습니다.\n",
    "\n",
    "\n",
    "### Class 9: Recon_C2\n",
    "![Benign WordCloud](./wordcloud_by_class/inaccuracy_wordcloud_9_Recon_C2.png)\n",
    "#### 주요 단어\n",
    "- protocol, possibly, search, structure, det, read, signature, custom, status\n",
    "\n",
    "#### 해석\n",
    "Reconnaissance(정찰) 및 C2(명령제어) 행위가 섞인 클래스입니다.\n",
    "`search`, `possibly`, `custom`, `protocol`, `signature` 등은 탐지된 트래픽이 명확한 악성 행위보다는 **의심스러운 요청** 또는 **비표준 포맷**을 가진 경우일 수 있습니다.\n",
    "`custom`, `structure`, `entropy` 등의 단어는 비정형 트래픽(예: 특수 제작된 C2 패킷)을 나타낼 수 있고,\n",
    "모델이 공격의 명확한 패턴을 잡기 어려운 상황에서 benign으로 판단해 오탐된 것으로 추정됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7b302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_tokens(tokens, top_n=10):\n",
    "    counter = Counter(tokens)\n",
    "    return counter.most_common(top_n)\n",
    "\n",
    "# 클래스별 토큰 저장된 dict 사용: wordcloud_tokens_by_class[class_id] = [token1, token2, ...]\n",
    "selected_classes = {\n",
    "    0: \"Benign\",\n",
    "    1: \"Banking_Emotet_Family\",\n",
    "    3: \"Banking_Other\",\n",
    "    9: \"Recon_C2\"\n",
    "}\n",
    "\n",
    "top10_by_class = {}\n",
    "\n",
    "for class_id, label in selected_classes.items():\n",
    "    tokens = wordcloud_tokens_by_class[class_id]  # ← 각 클래스별 토큰 리스트\n",
    "    top10_by_class[label] = get_top_tokens(tokens, top_n=10)\n",
    "\n",
    "# 출력\n",
    "import pandas as pd\n",
    "\n",
    "df_top10 = pd.DataFrame.from_dict(top10_by_class, orient=\"index\").T\n",
    "df_top10.columns.name = \"Class\"\n",
    "display(df_top10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e42aa03",
   "metadata": {},
   "source": [
    "## Word Frequency Top-10 by Class (디코딩 기반 WordCloud 분석)\n",
    "\n",
    "각 클래스에서 추출된 디코딩 텍스트를 기반으로 토큰화한 결과, 등장 빈도가 높은 상위 10개 단어를 추출하였습니다.  \n",
    "이 분석은 SHAP이나 LIME과 같은 복잡한 모델 해석 기법 대신, 초심자도 이해하기 쉬운 방식으로  \n",
    "\"모델이 어떤 단어를 중심으로 예측했는가\"를 간접적으로 해석하기 위한 용도입니다.\n",
    "\n",
    "---\n",
    "\n",
    "### Class 0: Benign\n",
    "| 순위 | 단어     | 빈도수 |\n",
    "|------|----------|--------|\n",
    "| 1    | `byte`   | 274    |\n",
    "| 2    | `data`   | 242    |\n",
    "| 3    | `det`    | 214    |\n",
    "| 4    | `protocol` | 213  |\n",
    "| 5    | `en`     | 183    |\n",
    "| 6    | `length` | 168    |\n",
    "| 7    | `read`   | 129    |\n",
    "| 8    | `http`   | 120    |\n",
    "| 9    | `entro`  | 111    |\n",
    "| 10   | `status` | 111    |\n",
    "\n",
    "- **해석**: benign 데이터에서는 일반적인 네트워크 구조 정보(`byte`, `protocol`, `length`, `status`)가 주로 등장하며,  \n",
    "  민감하거나 명시적인 악성 동작을 의미하는 특이 패턴은 적음. 단어 `http`도 정상 통신의 흔한 구조로 볼 수 있음.\n",
    "\n",
    "---\n",
    "\n",
    "### Class 1: Banking_Emotet_Family\n",
    "| 순위 | 단어       | 빈도수 |\n",
    "|------|------------|--------|\n",
    "| 1    | `protocol` | 3288   |\n",
    "| 2    | `det`      | 3278   |\n",
    "| 3    | `data`     | 3246   |\n",
    "| 4    | `byte`     | 2804   |\n",
    "| 5    | `read`     | 2321   |\n",
    "| 6    | `en`       | 2014   |\n",
    "| 7    | `quer`     | 1925   |\n",
    "| 8    | `length`   | 1839   |\n",
    "| 9    | `id`       | 1538   |\n",
    "| 10   | `answer`   | 1459   |\n",
    "\n",
    "- **해석**: `quer`, `id`, `answer` 등의 요청/응답 구조는 C2 서버 또는 피싱 시나리오에서 발생하는 행동일 가능성 있음.  \n",
    "  `det`, `protocol`, `data` 등도 Emotet 악성 모듈이 활용하는 네트워크 통신 구조를 나타낼 수 있음.\n",
    "\n",
    "---\n",
    "\n",
    "### Class 2: Banking_Other\n",
    "| 순위 | 단어       | 빈도수 |\n",
    "|------|------------|--------|\n",
    "| 1    | `data`     | 16818  |\n",
    "| 2    | `byte`     | 11831  |\n",
    "| 3    | `protocol` | 11295  |\n",
    "| 4    | `det`      | 11289  |\n",
    "| 5    | `http`     | 9830   |\n",
    "| 6    | `read`     | 9368   |\n",
    "| 7    | `en`       | 8299   |\n",
    "| 8    | `length`   | 7023   |\n",
    "| 9    | `possibly` | 5867   |\n",
    "| 10   | `status`   | 5860   |\n",
    "\n",
    "- **해석**: 일반적인 Banking 관련 악성코드에서도 `http`, `read`, `possibly`와 같이  \n",
    "  의심스러운 다운로드, 정보 수집, 의도된 리다이렉션과 관련된 단어들이 자주 나타남.\n",
    "\n",
    "---\n",
    "\n",
    "### Class 9: Recon_C2\n",
    "| 순위 | 단어       | 빈도수 |\n",
    "|------|------------|--------|\n",
    "| 1    | `data`     | 6601   |\n",
    "| 2    | `protocol` | 5427   |\n",
    "| 3    | `byte`     | 4612   |\n",
    "| 4    | `possibly` | 4229   |\n",
    "| 5    | `en`       | 4084   |\n",
    "| 6    | `det`      | 3921   |\n",
    "| 7    | `read`     | 3671   |\n",
    "| 8    | `length`   | 2748   |\n",
    "| 9    | `entro`    | 2504   |\n",
    "| 10   | `status`   | 2504   |\n",
    "\n",
    "- **해석**: Recon_C2 클래스에서는 `possibly`, `det`, `entro` 등의 불확실성/탐지 지표가 반복적으로 등장하며,  \n",
    "  이는 탐색 및 명령제어(C2) 단계에서의 정보 수집 및 은폐 시도 가능성을 시사함.\n",
    "\n",
    "---\n",
    "\n",
    "이러한 분석은 **정확한 단어의 의미보다는 상대적인 등장 빈도와 조합**을 통해  \n",
    "\"어떤 클래스가 어떤 단어 패턴에 민감한가\"를 이해하는 데 목적이 있습니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nis2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
